{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22d95c0-bbd5-45e7-aa72-39c2bff45308",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=OSqIP-mOWOI&list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN&index=4&pp=iAQB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f489620-5179-4113-84d9-d5f2f7aeaeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Layer2:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "torch.Size([200, 100])\n",
      "Parameter containing:\n",
      "tensor([[-0.0858, -0.0893, -0.0389,  ...,  0.0647, -0.0460,  0.0464],\n",
      "        [ 0.0979, -0.0645,  0.0183,  ..., -0.0590, -0.0326, -0.0422],\n",
      "        [-0.0435,  0.0732,  0.0272,  ..., -0.0437,  0.0120,  0.0695],\n",
      "        ...,\n",
      "        [-0.0101,  0.0499, -0.0034,  ..., -0.0111, -0.0587, -0.0748],\n",
      "        [-0.0477,  0.0664,  0.0539,  ...,  0.0105, -0.0693, -0.0506],\n",
      "        [ 0.0350,  0.0160,  0.0005,  ...,  0.0224, -0.0477,  0.0353]],\n",
      "       requires_grad=True)\n",
      "torch.Size([200])\n",
      "Parameter containing:\n",
      "tensor([ 0.0182, -0.0069,  0.0473,  0.0671,  0.0877,  0.0522, -0.0824,  0.0560,\n",
      "         0.0477, -0.0119, -0.0361,  0.0881, -0.0270, -0.0897, -0.0238,  0.0843,\n",
      "        -0.0383, -0.0949,  0.0755,  0.0452, -0.0664, -0.0672,  0.0454,  0.0192,\n",
      "        -0.0749, -0.0482,  0.0088, -0.0485, -0.0448, -0.0368, -0.0758, -0.0041,\n",
      "        -0.0881,  0.0214, -0.0321, -0.0938, -0.0042, -0.0414,  0.0529,  0.0642,\n",
      "        -0.0041,  0.0132, -0.0658,  0.0781, -0.0934, -0.0705, -0.0534, -0.0275,\n",
      "         0.0914, -0.0855,  0.0055, -0.0475, -0.0881, -0.0121,  0.0420, -0.0337,\n",
      "         0.0219, -0.0700,  0.0553, -0.0193, -0.0432, -0.0297,  0.0410, -0.0336,\n",
      "         0.0926, -0.0754,  0.0298,  0.0324,  0.0009,  0.0615,  0.0532,  0.0519,\n",
      "        -0.0874,  0.0308, -0.0184,  0.0662,  0.0498,  0.0616,  0.0804,  0.0255,\n",
      "         0.0046,  0.0503, -0.0794, -0.0282, -0.0805, -0.0083,  0.0791, -0.0641,\n",
      "         0.0506,  0.0212,  0.0719,  0.0144,  0.0816,  0.0612,  0.0442,  0.0820,\n",
      "         0.0730,  0.0945,  0.0902,  0.0182, -0.0855, -0.0814, -0.0417,  0.0495,\n",
      "         0.0052, -0.0285, -0.0674,  0.0253, -0.0772, -0.0811,  0.0369, -0.0466,\n",
      "         0.0375, -0.0491, -0.0382,  0.0690, -0.0076, -0.0189,  0.0316, -0.0254,\n",
      "         0.0174, -0.0974,  0.0466,  0.0968,  0.0938, -0.0259,  0.0072, -0.0782,\n",
      "         0.0957, -0.0981,  0.0456, -0.0658, -0.0557,  0.0281, -0.0016, -0.0418,\n",
      "         0.0205, -0.0139, -0.0590,  0.0505,  0.0354, -0.0491, -0.0315,  0.0515,\n",
      "         0.0237, -0.0090,  0.0085,  0.0080,  0.0583,  0.0734,  0.0663, -0.0705,\n",
      "         0.0490,  0.0511,  0.0766, -0.0865, -0.0332,  0.0126,  0.0854, -0.0734,\n",
      "        -0.0457, -0.0846, -0.0409, -0.0181, -0.0300,  0.0784, -0.0985,  0.0311,\n",
      "         0.0796, -0.0983, -0.0951, -0.0206,  0.0428, -0.0236, -0.0218,  0.0032,\n",
      "         0.0733,  0.0506,  0.0313, -0.0819, -0.0714, -0.0334, -0.0698, -0.0839,\n",
      "         0.0870, -0.0779,  0.0893,  0.0673,  0.0140, -0.0794, -0.0626, -0.0318,\n",
      "         0.0482,  0.0032,  0.0939,  0.0335,  0.0038, -0.0706, -0.0465, -0.0494],\n",
      "       requires_grad=True)\n",
      "torch.Size([10, 200])\n",
      "Parameter containing:\n",
      "tensor([[-0.0358, -0.0400, -0.0307,  ..., -0.0450, -0.0458, -0.0162],\n",
      "        [ 0.0700,  0.0456, -0.0525,  ...,  0.0251,  0.0008,  0.0663],\n",
      "        [ 0.0050, -0.0539,  0.0278,  ...,  0.0684, -0.0020,  0.0623],\n",
      "        ...,\n",
      "        [ 0.0687,  0.0109, -0.0046,  ..., -0.0316, -0.0502, -0.0398],\n",
      "        [ 0.0517, -0.0101,  0.0535,  ..., -0.0031, -0.0298,  0.0509],\n",
      "        [ 0.0594,  0.0198, -0.0535,  ..., -0.0623, -0.0629,  0.0627]],\n",
      "       requires_grad=True)\n",
      "torch.Size([10])\n",
      "Parameter containing:\n",
      "tensor([-0.0668, -0.0435, -0.0552,  0.0349,  0.0173,  0.0250,  0.0273,  0.0417,\n",
      "        -0.0459,  0.0139], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer2 params:\n",
      "torch.Size([10, 200])\n",
      "Parameter containing:\n",
      "tensor([[-0.0358, -0.0400, -0.0307,  ..., -0.0450, -0.0458, -0.0162],\n",
      "        [ 0.0700,  0.0456, -0.0525,  ...,  0.0251,  0.0008,  0.0663],\n",
      "        [ 0.0050, -0.0539,  0.0278,  ...,  0.0684, -0.0020,  0.0623],\n",
      "        ...,\n",
      "        [ 0.0687,  0.0109, -0.0046,  ..., -0.0316, -0.0502, -0.0398],\n",
      "        [ 0.0517, -0.0101,  0.0535,  ..., -0.0031, -0.0298,  0.0509],\n",
      "        [ 0.0594,  0.0198, -0.0535,  ..., -0.0623, -0.0629,  0.0627]],\n",
      "       requires_grad=True)\n",
      "torch.Size([10])\n",
      "Parameter containing:\n",
      "tensor([-0.0668, -0.0435, -0.0552,  0.0349,  0.0173,  0.0250,  0.0273,  0.0417,\n",
      "        -0.0459,  0.0139], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nLayer2:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param.shape)\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer2 params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param.shape)\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36d2bd-5eeb-47f6-96e2-f8390b7a50e2",
   "metadata": {},
   "source": [
    "## Common Layer Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f3fecf2-6d21-4b13-a5a2-21847a3a8ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.1954, 0.1121, 0.4606]])\n",
      "\n",
      "\n",
      "Weight and Bias Parameters:\n",
      "torch.Size([2, 3])\n",
      "Parameter containing:\n",
      "tensor([[-0.5050, -0.5167,  0.4285],\n",
      "        [ 0.0127,  0.3596, -0.2269]], requires_grad=True)\n",
      "torch.Size([2])\n",
      "Parameter containing:\n",
      "tensor([-0.5326, -0.4200], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[-0.4918, -0.4817]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3,2)\n",
    "x = torch.rand(1,3)\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias Parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param.shape)\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb1951-2917-43ca-98c4-cf72eb5e4850",
   "metadata": {},
   "source": [
    "### Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22642249-2c17-490f-b9da-20f948a8dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # 1 input image channel (black & white), 6 output channels, 3x3 square convolution kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16*6*6, 120) # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2,2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        # If the size is a square, you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fbf5dd-196a-4f1b-9a66-75b84d5d1c96",
   "metadata": {},
   "source": [
    "### Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a213b45f-302e-450e-9451-1a21deb907a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4fc22-de5f-4932-8e79-e2245780ddbd",
   "metadata": {},
   "source": [
    "## Other Layers and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c51f2a69-ac17-4db8-b9a2-bf3112b6a8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9057, 0.3819, 0.6223, 0.1159, 0.6162, 0.1379],\n",
      "         [0.7229, 0.8933, 0.8230, 0.1987, 0.7447, 0.7009],\n",
      "         [0.5246, 0.8361, 0.8915, 0.9797, 0.0393, 0.3456],\n",
      "         [0.4692, 0.7562, 0.3610, 0.6188, 0.5126, 0.4137],\n",
      "         [0.5575, 0.3412, 0.1996, 0.7662, 0.4150, 0.7437],\n",
      "         [0.8331, 0.1640, 0.2648, 0.3901, 0.9983, 0.8148]]])\n",
      "tensor([[[0.9057, 0.9797],\n",
      "         [0.8331, 0.9983]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1,6,6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "942f2829-53dd-4fe6-835b-7cc62b78c26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[14.9145,  8.4515, 20.2624, 18.6193],\n",
      "         [14.2996, 11.0874, 23.5475, 10.1099],\n",
      "         [10.3311, 22.7006,  5.0069, 15.2135],\n",
      "         [14.8861,  5.8449, 11.4248,  6.2728]]])\n",
      "tensor(13.3108)\n",
      "tensor([[[-0.1426, -1.5664,  1.0355,  0.6735],\n",
      "         [-0.0870, -0.6926,  1.6565, -0.8769],\n",
      "         [-0.4579,  1.4416, -1.2755,  0.2918],\n",
      "         [ 1.4053, -1.0015,  0.4839, -0.8876]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(-2.2352e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1,4,4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f7955a5-416f-494b-8308-32f459cb919f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4462, 0.5660, 0.3722, 0.7879],\n",
      "         [0.5048, 0.0812, 0.9505, 0.5933],\n",
      "         [0.0241, 0.7332, 0.6322, 0.7899],\n",
      "         [0.8347, 0.0732, 0.8985, 0.0033]]])\n",
      "tensor([[[0.0000, 0.9434, 0.6203, 1.3131],\n",
      "         [0.8414, 0.1353, 0.0000, 0.9888],\n",
      "         [0.0402, 1.2219, 1.0536, 0.0000],\n",
      "         [1.3911, 0.1220, 0.0000, 0.0000]]])\n",
      "tensor([[[0.7437, 0.0000, 0.6203, 0.0000],\n",
      "         [0.8414, 0.0000, 1.5842, 0.9888],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.1220, 0.0000, 0.0055]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1,4,4)\n",
    "print(my_tensor)\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.4)\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1cbd49-9c21-4211-af69-61dc34e1a44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
